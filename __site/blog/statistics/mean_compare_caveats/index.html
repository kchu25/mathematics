<!doctype html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
   <link rel="stylesheet" href="/libs/katex/katex.min.css">
     
   <link rel="stylesheet" href="/libs/highlight/styles/github.min.css">
   
  <link rel="stylesheet" href="/css/franklin.css">
<link rel="stylesheet" href="/css/hypertext.css">
<link rel="icon" href="/assets/favicon.png">

   <title>Sample Size for Comparing Population Means</title>  
</head>
<body>
<header>
  <h1 style="color:#283747">Mathematics</h1>
  <nav>
    <a href="/" class="current">Tags</a>
  | <a href="/blog/" >Notes</a>
  <hr/>
  </nav>
</header>


<!-- Content appended here -->
<div class="franklin-content"><h1 id="sample_size_for_comparing_population_means"><a href="#sample_size_for_comparing_population_means" class="header-anchor">Sample Size for Comparing Population Means</a></h1>
<h2 id="key_question"><a href="#key_question" class="header-anchor">Key Question</a></h2>
<p><strong>How many samples do I need per group to meaningfully compare population means?</strong></p>
<p><strong>Answer:</strong> No fixed minimum‚Äîit depends on:</p>
<ul>
<li><p>Effect size you want to detect</p>
</li>
<li><p>Within-group variability</p>
</li>
<li><p>Significance level &#40;Œ±&#41;</p>
</li>
<li><p>Desired statistical power &#40;1‚àíŒ≤&#41;</p>
</li>
</ul>
<blockquote>
<p><strong>üìã What Statistical Tests Does This Apply To?</strong></p>
<p><strong>YES - These calculations apply to:</strong></p>
<ul>
<li><p><strong>Independent samples t-test</strong> &#40;two groups, different subjects&#41; ‚úì</p>
</li>
<li><p><strong>Paired t-test</strong> &#40;two measurements, same subjects&#41; - but more powerful &#40;see note below&#41;</p>
</li>
<li><p><strong>One-way ANOVA</strong> &#40;multiple groups&#41; - with modifications for multiple comparisons</p>
</li>
<li><p><strong>Z-test</strong> &#40;when population variance is known&#41;</p>
</li>
<li><p><strong>Mann-Whitney U test / Wilcoxon</strong> &#40;non-parametric alternatives&#41; - approximately</p>
</li>
</ul>
<p><strong>The formulas in this document are specifically derived for:</strong></p>
<ul>
<li><p>Two independent groups</p>
</li>
<li><p>Normal distributions &#40;or large enough n for Central Limit Theorem&#41;</p>
</li>
<li><p>Equal variances &#40;pooled variance assumption&#41;</p>
</li>
<li><p>Two-sided tests</p>
</li>
</ul>
<p><strong>Important notes:</strong></p>
<ul>
<li><p><strong>t-test vs z-test</strong>: At n‚â•30, t-distribution ‚âà normal distribution, so formulas using Z-values are accurate approximations</p>
</li>
<li><p><strong>Paired t-test</strong>: Much more powerful&#33; Effective sample size increases by factor of \(1/(1-\rho)\) where \(\rho\) is correlation between paired measurements</p>
</li>
<li><p><strong>Non-parametric tests</strong>: Slightly less powerful than t-tests when data is normal; may need ~5-15&#37; more samples</p>
</li>
<li><p><strong>ANOVA with &gt;2 groups</strong>: Use similar principles but adjust for multiple comparisons &#40;use Cohen&#39;s f instead of d&#41;</p>
</li>
</ul>
<p><strong>Bottom line</strong>: These power calculations are most accurate for independent samples t-tests, but the general principles &#40;more samples &#61; detect smaller effects&#41; apply to all comparison tests.</p>
</blockquote>
<hr />
<h2 id="workflow_checking_if_your_unequal_samples_are_adequate"><a href="#workflow_checking_if_your_unequal_samples_are_adequate" class="header-anchor">Workflow: Checking If Your Unequal Samples Are Adequate</a></h2>
<h3 id="scenario_you_already_have_data"><a href="#scenario_you_already_have_data" class="header-anchor">Scenario: You Already Have Data</a></h3>
<p><strong>You have:</strong> Group 1 with n‚ÇÅ samples, Group 2 with n‚ÇÇ samples</p>
<p><strong>Question:</strong> &quot;Do I have enough samples to detect a meaningful difference?&quot;</p>
<blockquote>
<p><strong>‚ö†Ô∏è Common Confusion: Planning vs. Checking</strong></p>
<p><strong>Two different scenarios:</strong></p>
<p><strong>SCENARIO A - PLANNING &#40;before data collection&#41;:</strong></p>
<ul>
<li><p>Question: &quot;How many samples do I need to collect?&quot;</p>
</li>
<li><p>Use formula: \(n = 15.68/d^2\) to calculate required sample size</p>
</li>
<li><p>You decide Œ¥ and œÉ beforehand ‚Üí get d ‚Üí calculate n</p>
</li>
</ul>
<p><strong>SCENARIO B - CHECKING &#40;after data collection&#41;:</strong></p>
<ul>
<li><p>Question: &quot;I already have n‚ÇÅ and n‚ÇÇ samples - are they enough?&quot;</p>
</li>
<li><p>Calculate: \(d_{\min} = 2.8/\sqrt{n_{\text{eff}}}\) to find what you CAN detect</p>
</li>
<li><p>Compare d_min to your expected effect size d</p>
</li>
<li><p><strong>This is the workflow below&#33;</strong></p>
</li>
</ul>
<p><strong>Key difference:</strong> </p>
<ul>
<li><p>Planning: Œ¥, œÉ ‚Üí d ‚Üí <strong>n</strong> &#40;you&#39;re solving for sample size&#41;</p>
</li>
<li><p>Checking: n‚ÇÅ, n‚ÇÇ ‚Üí n<em>eff ‚Üí **d</em>min** &#40;you&#39;re solving for detectable effect&#41;</p>
</li>
</ul>
</blockquote>
<h3 id="step-by-step_workflow"><a href="#step-by-step_workflow" class="header-anchor">Step-by-Step Workflow</a></h3>
<h4 id="step_1_calculate_effective_sample_size"><a href="#step_1_calculate_effective_sample_size" class="header-anchor"><strong>Step 1: Calculate Effective Sample Size</strong></a></h4>
\[n_{\text{eff}} = \frac{2n_1 n_2}{n_1 + n_2}\]
<p><strong>Example:</strong> n‚ÇÅ &#61; 45, n‚ÇÇ &#61; 30</p>
\[n_{\text{eff}} = \frac{2 \times 45 \times 30}{45 + 30} = \frac{2700}{75} = 36\]
<hr />
<h4 id="step_2_calculate_pooled_standard_deviation"><a href="#step_2_calculate_pooled_standard_deviation" class="header-anchor"><strong>Step 2: Calculate Pooled Standard Deviation</strong></a></h4>
<p>From your actual data, calculate the standard deviations s‚ÇÅ and s‚ÇÇ for each group, then:</p>
\[\sigma_{\text{pooled}} = \sqrt{\frac{(n_1-1)s_1^2 + (n_2-1)s_2^2}{n_1 + n_2 - 2}}\]
<p><strong>Example:</strong> n‚ÇÅ&#61;45, s‚ÇÅ&#61;8.5; n‚ÇÇ&#61;30, s‚ÇÇ&#61;9.2</p>
\[\sigma_{\text{pooled}} = \sqrt{\frac{44 \times 72.25 + 29 \times 84.64}{73}} = \sqrt{\frac{5633.56}{73}} \approx 8.78\]
<hr />
<h4 id="step_3_decide_your_minimum_meaningful_difference_Œ¥"><a href="#step_3_decide_your_minimum_meaningful_difference_Œ¥" class="header-anchor"><strong>Step 3: Decide Your Minimum Meaningful Difference &#40;Œ¥&#41;</strong></a></h4>
<p><strong>This is subjective and domain-specific&#33;</strong></p>
<p>Ask yourself: &quot;What&#39;s the smallest difference that would matter in practice?&quot;</p>
<p><strong>Example:</strong> Comparing test scores</p>
<ul>
<li><p>If a 2-point difference doesn&#39;t matter clinically/practically ‚Üí Œ¥ &#61; 2 is too small</p>
</li>
<li><p>If a 5-point difference is meaningful ‚Üí set Œ¥ &#61; 5</p>
</li>
</ul>
<hr />
<h4 id="step_4_calculate_expected_cohens_d"><a href="#step_4_calculate_expected_cohens_d" class="header-anchor"><strong>Step 4: Calculate Expected Cohen&#39;s d</strong></a></h4>
\[d = \frac{\delta}{\sigma_{\text{pooled}}}\]
<p><strong>Example:</strong> Œ¥ &#61; 5, œÉ &#61; 8.78</p>
\[d = \frac{5}{8.78} \approx 0.57\]
<p>This is a medium-to-large effect.</p>
<hr />
<h4 id="step_5_calculate_minimum_detectable_cohens_d"><a href="#step_5_calculate_minimum_detectable_cohens_d" class="header-anchor"><strong>Step 5: Calculate Minimum Detectable Cohen&#39;s d</strong></a></h4>
<p>This tells you what your current sample can actually detect:</p>
\(d_{\min} = \frac{Z_{1-\alpha/2} + Z_{1-\beta}}{\sqrt{n_{\text{eff}}/2}}\)
<p>For Œ±&#61;0.05, 80&#37; power, this simplifies to:</p>
\(d_{\min} = \frac{2.8}{\sqrt{n_{\text{eff}}}}\)
<blockquote>
<p><strong>üìä Where Does the 2.8 Come From?</strong></p>
<p>The coefficient 2.8 comes from: \(Z_{1-\alpha/2} + Z_{1-\beta} = 1.96 + 0.84 = 2.80\)</p>
<p><strong>Assumptions built into this coefficient:</strong></p>
<ul>
<li><p><strong>Œ± &#61; 0.05</strong> &#40;two-sided test, 5&#37; significance level&#41;</p>
</li>
<li><p><strong>Power &#61; 80&#37;</strong> &#40;Œ≤ &#61; 0.20, so 20&#37; chance of Type II error&#41;</p>
</li>
</ul>
<p><strong>For different assumptions, use different coefficients:</strong></p>
<table><tr><th align="right">Œ± &#40;two-sided&#41;</th><th align="right">Power</th><th align="right">\(Z_{1-\alpha/2}\)</th><th align="right">\(Z_{1-\beta}\)</th><th align="right">Coefficient</th></tr><tr><td align="right">0.10</td><td align="right">70&#37;</td><td align="right">1.645</td><td align="right">0.524</td><td align="right"><strong>2.17</strong></td></tr><tr><td align="right">0.05</td><td align="right">70&#37;</td><td align="right">1.960</td><td align="right">0.524</td><td align="right"><strong>2.48</strong></td></tr><tr><td align="right"><strong>0.05</strong></td><td align="right"><strong>80&#37;</strong></td><td align="right"><strong>1.960</strong></td><td align="right"><strong>0.842</strong></td><td align="right"><strong>2.80</strong></td></tr><tr><td align="right">0.05</td><td align="right">90&#37;</td><td align="right">1.960</td><td align="right">1.282</td><td align="right"><strong>3.24</strong></td></tr><tr><td align="right">0.05</td><td align="right">95&#37;</td><td align="right">1.960</td><td align="right">1.645</td><td align="right"><strong>3.61</strong></td></tr><tr><td align="right">0.01</td><td align="right">80&#37;</td><td align="right">2.576</td><td align="right">0.842</td><td align="right"><strong>3.42</strong></td></tr><tr><td align="right">0.01</td><td align="right">90&#37;</td><td align="right">2.576</td><td align="right">1.282</td><td align="right"><strong>3.86</strong></td></tr></table>
<p><strong>Example:</strong> For 90&#37; power with Œ±&#61;0.05: \(d_{\min} = \frac{3.24}{\sqrt{n_{\text{eff}}}}\)</p>
<p><strong>Key insight:</strong> Higher power or lower Œ± ‚Üí larger coefficient ‚Üí larger d_min ‚Üí need more samples to achieve that power/significance level.</p>
</blockquote>
<p><strong>Example:</strong> n_eff &#61; 36, using standard assumptions &#40;Œ±&#61;0.05, 80&#37; power&#41; \(d_{\min} = \frac{2.8}{\sqrt{36}} = \frac{2.8}{6} \approx 0.47\)</p>
<hr />
<h4 id="reference_table_minimum_detectable_d_for_common_sample_sizes"><a href="#reference_table_minimum_detectable_d_for_common_sample_sizes" class="header-anchor"><strong>Reference Table: Minimum Detectable d for Common Sample Sizes</strong></a></h4>
<p>Using standard assumptions &#40;Œ±&#61;0.05, 80&#37; power, two-sided&#41;:</p>
<table><tr><th align="right">n_eff</th><th align="right">d_min</th><th align="right">Interpretation</th></tr><tr><td align="right">10</td><td align="right">0.89</td><td align="right">Very large effects only</td></tr><tr><td align="right">15</td><td align="right">0.72</td><td align="right">Large effects only</td></tr><tr><td align="right">20</td><td align="right">0.63</td><td align="right">Large effects</td></tr><tr><td align="right">25</td><td align="right">0.56</td><td align="right">Medium-large effects</td></tr><tr><td align="right">30</td><td align="right">0.51</td><td align="right">Medium effects</td></tr><tr><td align="right">40</td><td align="right">0.44</td><td align="right">Medium effects</td></tr><tr><td align="right">50</td><td align="right">0.40</td><td align="right">Small-medium effects</td></tr><tr><td align="right">64</td><td align="right">0.35</td><td align="right">Small-medium effects</td></tr><tr><td align="right">80</td><td align="right">0.31</td><td align="right">Small-medium effects</td></tr><tr><td align="right">100</td><td align="right">0.28</td><td align="right">Small effects</td></tr><tr><td align="right">150</td><td align="right">0.23</td><td align="right">Small effects</td></tr><tr><td align="right">200</td><td align="right">0.20</td><td align="right">Small effects</td></tr><tr><td align="right">300</td><td align="right">0.16</td><td align="right">Very small effects</td></tr><tr><td align="right">400</td><td align="right">0.14</td><td align="right">Very small effects</td></tr></table>
<p><strong>How to use this table:</strong></p>
<ol>
<li><p>Calculate your n_eff from your actual sample sizes</p>
</li>
<li><p>Find the closest n_eff in the table</p>
</li>
<li><p>Check if d_min is reasonable for your expected effect</p>
</li>
<li><p>If your expected d &gt; d_min ‚Üí you&#39;re good&#33;</p>
</li>
<li><p>If your expected d &lt; d_min ‚Üí underpowered</p>
</li>
</ol>
<hr />
<h4 id="step_6_compare_and_decide"><a href="#step_6_compare_and_decide" class="header-anchor"><strong>Step 6: Compare and Decide</strong></a></h4>
<p><strong>Decision Rule:</strong></p>
<table><tr><th align="right">Comparison</th><th align="right">Interpretation</th><th align="right">Action</th></tr><tr><td align="right"><strong>d &#40;expected&#41; &gt; d_min</strong></td><td align="right">‚úì You have enough power</td><td align="right">Proceed with analysis</td></tr><tr><td align="right"><strong>d &#40;expected&#41; ‚âà d_min</strong></td><td align="right">‚ö†Ô∏è Borderline power &#40;~80&#37;&#41;</td><td align="right">Proceed but note limitations</td></tr><tr><td align="right"><strong>d &#40;expected&#41; &lt; d_min</strong></td><td align="right">‚úó Underpowered</td><td align="right">Results unreliable; need more data</td></tr></table>
<p><strong>In our example:</strong></p>
<ul>
<li><p>Expected d &#61; 0.57</p>
</li>
<li><p>Minimum detectable d_min &#61; 0.47</p>
</li>
<li><p><strong>0.57 &gt; 0.47</strong> ‚Üí ‚úì <strong>You have adequate power&#33;</strong></p>
</li>
</ul>
<blockquote>
<p><strong>‚úçÔ∏è How to Report Your Power Analysis</strong></p>
<p><strong>After confirming adequate power, you should report this in your analysis. Here are standard ways to phrase it:</strong></p>
<p><strong>Option 1 - Simple statement:</strong> &quot;The sample means were compared using an independent samples t-test with 80&#37; power to detect a medium effect size &#40;d &#61; 0.5&#41; at Œ± &#61; 0.05.&quot;</p>
<p><strong>Option 2 - More detailed:</strong> &quot;Given sample sizes of n‚ÇÅ &#61; 45 and n‚ÇÇ &#61; 30 &#40;effective n &#61; 36&#41;, this study had 80&#37; power to detect an effect size of d ‚â• 0.47 at the Œ± &#61; 0.05 significance level.&quot;</p>
<p><strong>Option 3 - Full reporting &#40;recommended for publications&#41;:</strong> &quot;A post-hoc power analysis indicated that with n‚ÇÅ &#61; 45 and n‚ÇÇ &#61; 30, the study achieved 80&#37; power &#40;1-Œ≤ &#61; 0.80&#41; to detect a minimum effect size of Cohen&#39;s d &#61; 0.47 at Œ± &#61; 0.05 &#40;two-tailed&#41;. The expected effect size based on prior literature was d &#61; 0.57, confirming adequate statistical power.&quot;</p>
<p><strong>What NOT to say:</strong> ‚ùå &quot;The test was significant with p &lt; 0.05&quot; &#40;this doesn&#39;t mention power&#41; ‚ùå &quot;We had enough samples&quot; &#40;too vague&#41; ‚ùå &quot;Post-hoc power was 95&#37;&quot; after seeing significant results &#40;this is circular reasoning - see note below&#41;</p>
<p><strong>Important considerations:</strong></p>
<p><strong>1. A priori vs. post-hoc power:</strong></p>
<ul>
<li><p><strong>A priori &#40;before seeing results&#41;</strong>: Calculate power based on expected effect ‚Üí GOOD</p>
</li>
<li><p><strong>Post-hoc using observed effect</strong>: Calculate power after seeing your result ‚Üí PROBLEMATIC &#40;gives inflated sense of confidence&#41;</p>
</li>
<li><p><strong>Post-hoc using n<em>eff and d</em>min</strong>: Calculate what you COULD detect with your samples ‚Üí GOOD &#40;this is what we did above&#41;</p>
</li>
</ul>
<p><strong>2. If you find &quot;not significant&quot;:</strong></p>
<ul>
<li><p>Report power analysis to show whether you had adequate power to detect effects</p>
</li>
<li><p>Example: &quot;No significant difference was found &#40;p &#61; 0.12&#41;. However, with n_eff &#61; 36, the study only had 80&#37; power to detect effects of d ‚â• 0.47. Smaller effects may exist but were not detectable with this sample size.&quot;</p>
</li>
</ul>
<p><strong>3. If you&#39;re underpowered:</strong></p>
<ul>
<li><p>Be honest about limitations</p>
</li>
<li><p>Example: &quot;The sample sizes &#40;n‚ÇÅ &#61; 15, n‚ÇÇ &#61; 12, n_eff &#61; 13&#41; provided only 80&#37; power to detect very large effects &#40;d ‚â• 0.77&#41;. Results should be interpreted cautiously as smaller but meaningful effects may have been missed.&quot;</p>
</li>
</ul>
</blockquote>
<hr />
<h3 id="alternative_if_you_dont_know_Œ¥_yet"><a href="#alternative_if_you_dont_know_Œ¥_yet" class="header-anchor">Alternative: If You Don&#39;t Know Œ¥ Yet</a></h3>
<p><strong>If you haven&#39;t decided what difference matters</strong>, reverse the calculation:</p>
<h4 id="calculate_what_difference_your_sample_can_detect"><a href="#calculate_what_difference_your_sample_can_detect" class="header-anchor">Calculate what difference your sample CAN detect:</a></h4>
\[\delta_{\min} = d_{\min} \times \sigma_{\text{pooled}} = \frac{2.8}{\sqrt{n_{\text{eff}}}} \times \sigma_{\text{pooled}}\]
<p><strong>Example:</strong> n_eff &#61; 36, œÉ &#61; 8.78</p>
\[\delta_{\min} = 0.47 \times 8.78 \approx 4.1\]
<p><strong>Interpretation:</strong> &quot;With my current sample sizes, I can detect differences of 4.1 points or larger with 80&#37; power.&quot;</p>
<p><strong>Then ask:</strong> &quot;Is a 4.1-point difference meaningful in my field?&quot;</p>
<ul>
<li><p>If YES ‚Üí proceed</p>
</li>
<li><p>If NO &#40;you need to detect smaller differences&#41; ‚Üí need more samples</p>
</li>
</ul>
<hr />
<h3 id="quick_reference_workflow_chart"><a href="#quick_reference_workflow_chart" class="header-anchor">Quick Reference Workflow Chart</a></h3>
<pre><code class="language-julia">START: You have n‚ÇÅ and n‚ÇÇ samples
    ‚Üì
&#91;1&#93; Calculate n_eff &#61; 2n‚ÇÅn‚ÇÇ/&#40;n‚ÇÅ&#43;n‚ÇÇ&#41;
    ‚Üì
&#91;2&#93; Calculate œÉ_pooled from your data
    ‚Üì
&#91;3&#93; Decide: What&#39;s the minimum meaningful difference &#40;Œ¥&#41;?
    ‚Üì
&#91;4&#93; Calculate expected d &#61; Œ¥/œÉ_pooled
    ‚Üì
&#91;5&#93; Calculate d_min &#61; 2.8/‚àön_eff
    ‚Üì
&#91;6&#93; Compare: Is d &gt; d_min?
    ‚Üì
YES: ‚úì Adequate power ‚Üí Run your t-test
NO: ‚úó Underpowered ‚Üí Collect more data or reconsider</code></pre>
<hr />
<h3 id="common_mistakes_to_avoid"><a href="#common_mistakes_to_avoid" class="header-anchor">Common Mistakes to Avoid</a></h3>
<p>‚ùå <strong>WRONG:</strong> &quot;I&#39;ll calculate n_eff and use the formula n &#61; 15.68/d¬≤&quot;</p>
<ul>
<li><p>That formula is for <strong>planning</strong> sample size, not checking existing samples</p>
</li>
</ul>
<p>‚úì <strong>CORRECT:</strong> Use d<em>min &#61; 2.8/‚àön</em>eff to find what you <strong>can</strong> detect, then compare to what you <strong>want</strong> to detect</p>
<p>‚ùå <strong>WRONG:</strong> Setting Œ¥ based on what you observe in your data</p>
<ul>
<li><p>This is circular reasoning and invalidates your test</p>
</li>
</ul>
<p>‚úì <strong>CORRECT:</strong> Set Œ¥ based on prior knowledge, clinical significance, or practical importance <strong>before</strong> looking at your results</p>
<hr />
<h2 id="the_formula_for_planning_sample_size"><a href="#the_formula_for_planning_sample_size" class="header-anchor">The Formula &#40;For Planning Sample Size&#41;</a></h2>
<p>For <strong>two independent groups</strong> with equal sample sizes &#40;two-sided t-test&#41;:</p>
\[n = 2\left(\frac{Z_{1-\alpha/2} + Z_{1-\beta}}{\delta/\sigma}\right)^2\]
<p>Where:</p>
<ul>
<li><p>\(n\) &#61; sample size per group</p>
</li>
<li><p>\(Z_{1-\alpha/2}\) &#61; critical value for significance &#40;1.96 for Œ±&#61;0.05&#41;</p>
</li>
<li><p>\(Z_{1-\beta}\) &#61; critical value for power &#40;0.84 for 80&#37; power&#41;</p>
</li>
<li><p>\(\delta\) &#61; minimum detectable difference between means</p>
</li>
<li><p>\(\sigma\) &#61; pooled standard deviation</p>
</li>
</ul>
<blockquote>
<p><strong>üìè What is Œ¥ &#40;delta&#41; - Minimum Detectable Difference?</strong></p>
<p><strong>Œ¥</strong> is the smallest difference between group means that you care about detecting.</p>
<p><strong>Example</strong>: You&#39;re comparing blood pressure between two treatments.</p>
<ul>
<li><p>Group 1 mean: 120 mmHg</p>
</li>
<li><p>Group 2 mean: 115 mmHg</p>
</li>
<li><p>Difference: Œ¥ &#61; 5 mmHg</p>
</li>
</ul>
<p><strong>You decide</strong>: &quot;I only care if the difference is at least 5 mmHg. Smaller differences aren&#39;t clinically meaningful to me.&quot;</p>
<p>So Œ¥ &#61; 5 mmHg is your <strong>minimum detectable difference</strong>. Your sample size calculation ensures you have enough power to detect differences of this size &#40;or larger&#41;.</p>
<p><strong>Key point</strong>: You choose Œ¥ based on what matters in your field, not statistics&#33;</p>
</blockquote>
<blockquote>
<p><strong>üìê What is œÉ &#40;sigma&#41; - Pooled Standard Deviation?</strong></p>
<p><strong>œÉ</strong> measures how spread out &#40;variable&#41; your data is within each group.</p>
<p><strong>For equal sample sizes</strong> &#40;n‚ÇÅ &#61; n‚ÇÇ &#61; n&#41;:</p>
</blockquote>
\[\sigma = \sqrt{\frac{s_1^2 + s_2^2}{2}}\]
<blockquote>
<p><strong>For unequal sample sizes</strong>:</p>
</blockquote>
\[\sigma = \sqrt{\frac{(n_1-1)s_1^2 + (n_2-1)s_2^2}{n_1 + n_2 - 2}}\]
<blockquote>
<p>where \(s_1\) and \(s_2\) are the standard deviations of each group.</p>
<p><strong>Example</strong>: </p>
<ul>
<li><p>Group 1: SD &#61; 10 mmHg, n‚ÇÅ &#61; 30</p>
</li>
<li><p>Group 2: SD &#61; 12 mmHg, n‚ÇÇ &#61; 50</p>
</li>
<li><p>Pooled: \(\sigma = \sqrt{\frac{29 \times 100 + 49 \times 144}{78}} = \sqrt{\frac{9956}{78}} \approx 11.3\) mmHg</p>
</li>
</ul>
<p><strong>Why &quot;pooled&quot;?</strong> We&#39;re assuming both groups have similar variability, so we combine them into one estimate.</p>
</blockquote>
<blockquote>
<p><strong>üìä What is Statistical Power?</strong></p>
<p><strong>Power &#40;1‚àíŒ≤&#41;</strong> is the probability of detecting a real effect when it actually exists. In other words, it&#39;s your chance of avoiding a &quot;false negative.&quot;</p>
<p><strong>The Four Possible Outcomes:</strong></p>
<ul>
<li><p><strong>True Positive</strong> &#40;Power&#41;: Real effect exists ‚Üí Test detects it ‚úì</p>
</li>
<li><p><strong>False Negative</strong> &#40;Type II error, Œ≤&#41;: Real effect exists ‚Üí Test misses it ‚úó</p>
</li>
<li><p><strong>True Negative</strong>: No effect exists ‚Üí Test finds nothing ‚úì</p>
</li>
<li><p><strong>False Positive</strong> &#40;Type I error, Œ±&#41;: No effect exists ‚Üí Test claims one ‚úó</p>
</li>
</ul>
<p><strong>Power &#61; 80&#37;</strong> means: &quot;If there really is a difference of size Œ¥ between the groups, my test has an 80&#37; chance of finding it statistically significant.&quot;</p>
<p><strong>Why 80&#37;?</strong> Convention. Higher power &#40;90&#37;, 95&#37;&#41; is better but requires larger samples. Below 80&#37; is considered underpowered‚Äîyou&#39;re likely to miss real effects.</p>
<p><strong>Analogy</strong>: Think of power as the sensitivity of a metal detector. High power &#40;big sample&#41; &#61; detects small coins. Low power &#40;small sample&#41; &#61; only detects large objects.</p>
</blockquote>
<h3 id="simplified_formula_Œ±005_80_power"><a href="#simplified_formula_Œ±005_80_power" class="header-anchor">Simplified Formula &#40;Œ±&#61;0.05, 80&#37; power&#41;</a></h3>
\[n \approx 15.68\left(\frac{\sigma}{\delta}\right)^2\]
<p>Or equivalently, using Cohen&#39;s \(d = \delta/\sigma\):</p>
\[n \approx \frac{15.68}{d^2}\]
<blockquote>
<p><strong>üéØ What is Cohen&#39;s d - Standardized Effect Size?</strong></p>
<p><strong>Cohen&#39;s d</strong> is just the difference between means &#40;Œ¥&#41; divided by the standard deviation &#40;œÉ&#41;:</p>
</blockquote>
\[d = \frac{\delta}{\sigma} = \frac{\text{difference in means}}{\text{standard deviation}}\]
<blockquote>
<p><strong>Why use it?</strong> It&#39;s a &quot;standardized&quot; measure‚Äîtells you how big the effect is relative to the variability.</p>
<p><strong>Example</strong>:</p>
<ul>
<li><p>Blood pressure: Œ¥ &#61; 5 mmHg, œÉ &#61; 10 mmHg ‚Üí d &#61; 0.5 &#40;medium effect&#41;</p>
</li>
<li><p>Height: Œ¥ &#61; 5 cm, œÉ &#61; 10 cm ‚Üí d &#61; 0.5 &#40;also medium effect&#33;&#41;</p>
</li>
</ul>
<p>Even though 5 mmHg ‚â† 5 cm, both have d &#61; 0.5, so they&#39;re equally &quot;detectable&quot; statistically.</p>
<p><strong>Cohen&#39;s Guidelines:</strong></p>
<ul>
<li><p><strong>Small effect</strong>: d &#61; 0.2 &#40;difference is 20&#37; of one SD&#41;</p>
</li>
<li><p><strong>Medium effect</strong>: d &#61; 0.5 &#40;difference is 50&#37; of one SD&#41;</p>
</li>
<li><p><strong>Large effect</strong>: d &#61; 0.8 &#40;difference is 80&#37; of one SD&#41;</p>
</li>
</ul>
<p><strong>Intuition</strong>: </p>
<ul>
<li><p>d &#61; 1.0 means the two groups&#39; means are separated by one full standard deviation</p>
</li>
<li><p>Larger d &#61; easier to detect &#61; need fewer samples</p>
</li>
<li><p>Smaller d &#61; harder to detect &#61; need more samples</p>
</li>
</ul>
</blockquote>
<hr />
<h2 id="worked_examples_Œ±005_80_power"><a href="#worked_examples_Œ±005_80_power" class="header-anchor">Worked Examples &#40;Œ±&#61;0.05, 80&#37; power&#41;</a></h2>
<table><tr><th align="right">Effect Size</th><th align="right">Cohen&#39;s d</th><th align="right">\(\delta/\sigma\)</th><th align="right">n per group</th></tr><tr><td align="right"><strong>Large</strong></td><td align="right">0.8</td><td align="right">Œ¥ &#61; 0.8œÉ</td><td align="right"><strong>~25</strong></td></tr><tr><td align="right"><strong>Medium</strong></td><td align="right">0.5</td><td align="right">Œ¥ &#61; 0.5œÉ</td><td align="right"><strong>~63</strong></td></tr><tr><td align="right"><strong>Small</strong></td><td align="right">0.2</td><td align="right">Œ¥ &#61; 0.2œÉ</td><td align="right"><strong>~392</strong></td></tr></table>
<h3 id="interpretation"><a href="#interpretation" class="header-anchor">Interpretation</a></h3>
<ul>
<li><p><strong>Large effect</strong> &#40;difference equals 80&#37; of SD&#41;: Need ~25 samples per group</p>
</li>
<li><p><strong>Medium effect</strong> &#40;difference is 50&#37; of SD&#41;: Need ~63 samples per group  </p>
</li>
<li><p><strong>Small effect</strong> &#40;difference is 20&#37; of SD&#41;: Need ~392 samples per group</p>
</li>
</ul>
<hr />
<h2 id="important_considerations"><a href="#important_considerations" class="header-anchor">Important Considerations</a></h2>
<h3 id="paired_vs_independent_designs"><a href="#paired_vs_independent_designs" class="header-anchor"><ol>
<li><p><strong>Paired vs. Independent Designs</strong></p>
</li>
</ol>
</a></h3>
<ul>
<li><p><strong>Paired &#40;within-subject&#41;</strong>: Much more powerful; required \(n\) reduces by factor \((1-\rho)\) where \(\rho\) is the correlation between paired measurements</p>
</li>
<li><p>Use when measuring the same subjects under different conditions</p>
</li>
</ul>
<h3 id="ol_start2_multiple_groups_anova"><a href="#ol_start2_multiple_groups_anova" class="header-anchor"><ol start="2">
<li><p><strong>Multiple Groups &#40;ANOVA&#41;</strong></p>
</li>
</ol>
</a></h3>
<ul>
<li><p>Formula changes for &gt;2 groups</p>
</li>
<li><p>Use Cohen&#39;s \(f\) instead of Cohen&#39;s \(d\)</p>
</li>
<li><p>Requires ANOVA power calculator</p>
</li>
</ul>
<h3 id="ol_start3_multiple_comparisons"><a href="#ol_start3_multiple_comparisons" class="header-anchor"><ol start="3">
<li><p><strong>Multiple Comparisons</strong></p>
</li>
</ol>
</a></h3>
<ul>
<li><p>Adjust Œ± &#40;e.g., Bonferroni correction&#41;</p>
</li>
<li><p>Adjustment increases required sample size</p>
</li>
<li><p>Example: 5 comparisons ‚Üí Œ± &#61; 0.05/5 &#61; 0.01 per test</p>
</li>
</ul>
<h3 id="ol_start4_unequal_group_sizes_or_variances"><a href="#ol_start4_unequal_group_sizes_or_variances" class="header-anchor"><ol start="4">
<li><p><strong>Unequal Group Sizes or Variances</strong></p>
</li>
</ol>
</a></h3>
<ul>
<li><p>Formula adjustments needed</p>
</li>
<li><p>Power decreases with imbalanced groups</p>
</li>
<li><p>Use effective sample size &#40;harmonic mean&#41;</p>
</li>
<li><p>See detailed section below</p>
</li>
</ul>
<h3 id="ol_start5_unknown_variance"><a href="#ol_start5_unknown_variance" class="header-anchor"><ol start="5">
<li><p><strong>Unknown Variance</strong></p>
</li>
</ol>
</a></h3>
<ul>
<li><p>Estimate \(\sigma\) from pilot data or literature</p>
</li>
<li><p>Or specify effect size directly as Cohen&#39;s \(d\)</p>
</li>
</ul>
<hr />
<h2 id="if_your_sample_sizes_are_already_fixed"><a href="#if_your_sample_sizes_are_already_fixed" class="header-anchor">If Your Sample Sizes Are Already Fixed</a></h2>
<h3 id="question_i_have_n_and_n_samples_-_is_this_enough"><a href="#question_i_have_n_and_n_samples_-_is_this_enough" class="header-anchor">Question: &quot;I have n‚ÇÅ and n‚ÇÇ samples - is this enough?&quot;</a></h3>
<p>When sample sizes are fixed, you need to know: <strong>&quot;What size difference can my test reliably detect?&quot;</strong></p>
<h4 id="step_1_calculate_minimum_detectable_effect_size"><a href="#step_1_calculate_minimum_detectable_effect_size" class="header-anchor">Step 1: Calculate Minimum Detectable Effect Size</a></h4>
\[d_{\min} = \frac{Z_{1-\alpha/2} + Z_{1-\beta}}{\sqrt{n_{\text{eff}}/2}}\]
<p>where \(n_{\text{eff}} = \frac{2n_1 n_2}{n_1 + n_2}\) &#40;harmonic mean&#41;</p>
<p>For Œ±&#61;0.05, 80&#37; power:</p>
\[d_{\min} \approx \frac{2.8}{\sqrt{n_{\text{eff}}}}\]
<p><strong>What this means:</strong> </p>
<ul>
<li><p>\(d_{\min}\) is the <strong>minimum detectable effect size</strong> with 80&#37; power</p>
</li>
<li><p>Any effect size <strong>larger</strong> than \(d_{\min}\) will be <strong>even easier to detect</strong> &#40;higher power&#41;</p>
</li>
<li><p>Any effect size <strong>smaller</strong> than \(d_{\min}\) will have <strong>lower power</strong> &#40;more likely to miss it&#41;</p>
</li>
</ul>
<p><strong>In practice:</strong></p>
<ul>
<li><p>If your expected effect is \(d = 0.6\) and \(d_{\min} = 0.4\), you&#39;re good&#33; &#40;Your effect is larger ‚Üí easier to detect&#41;</p>
</li>
<li><p>If your expected effect is \(d = 0.3\) and \(d_{\min} = 0.4\), you&#39;re underpowered &#40;Your effect is smaller ‚Üí likely to miss it&#41;</p>
</li>
</ul>
<h4 id="step_2_compare_to_your_expected_effect"><a href="#step_2_compare_to_your_expected_effect" class="header-anchor">Step 2: Compare to Your Expected Effect</a></h4>
<table><tr><th align="right">Your Sample Sizes</th><th align="right">\(n_{\text{eff}}\)</th><th align="right">Min Detectable d</th><th align="right">Can Detect</th></tr><tr><td align="right">n‚ÇÅ&#61;30, n‚ÇÇ&#61;30</td><td align="right">30</td><td align="right">0.51</td><td align="right">Medium&#43; effects</td></tr><tr><td align="right">n‚ÇÅ&#61;50, n‚ÇÇ&#61;50</td><td align="right">50</td><td align="right">0.40</td><td align="right">Small-medium effects</td></tr><tr><td align="right">n‚ÇÅ&#61;100, n‚ÇÇ&#61;50</td><td align="right">67</td><td align="right">0.34</td><td align="right">Small-medium effects</td></tr><tr><td align="right">n‚ÇÅ&#61;100, n‚ÇÇ&#61;20</td><td align="right">33</td><td align="right">0.49</td><td align="right">Medium effects only</td></tr><tr><td align="right">n‚ÇÅ&#61;200, n‚ÇÇ&#61;200</td><td align="right">200</td><td align="right">0.20</td><td align="right">Small effects</td></tr></table>
<h3 id="what_this_actually_means"><a href="#what_this_actually_means" class="header-anchor">What This Actually Means</a></h3>
<p><strong>The problem</strong>: Even if a real difference exists, your test might say &quot;not significant&quot; if you don&#39;t have enough samples. This is called being &quot;underpowered.&quot;</p>
<p><strong>Think of it this way</strong>: </p>
<ul>
<li><p>You&#39;re comparing two groups</p>
</li>
<li><p>There IS a real difference between them</p>
</li>
<li><p>But your sample is too small, so the test says &quot;no significant difference&quot;</p>
</li>
<li><p>You conclude nothing is happening, but you&#39;re WRONG</p>
</li>
</ul>
<p><strong>How many samples do you need to avoid this?</strong></p>
<p>It depends on <strong>how big the real difference is</strong> &#40;relative to variability&#41;:</p>
<table><tr><th align="right">Your Sample Size</th><th align="right">Real difference you&#39;ll reliably detect</th></tr><tr><td align="right"><strong>10-15 per group</strong></td><td align="right">Only HUGE differences &#40;group means differ by ‚â•80&#37; of one SD&#41;</td></tr><tr><td align="right"><strong>30 per group</strong></td><td align="right">Large differences &#40;group means differ by ‚â•50&#37; of one SD&#41;</td></tr><tr><td align="right"><strong>50 per group</strong></td><td align="right">Medium differences &#40;group means differ by ‚â•40&#37; of one SD&#41;</td></tr><tr><td align="right"><strong>100&#43; per group</strong></td><td align="right">Small differences &#40;group means differ by ‚â•30&#37; of one SD&#41;</td></tr></table>
<p><strong>Example to make this concrete:</strong></p>
<p>Say you&#39;re comparing test scores &#40;SD &#61; 10 points&#41;:</p>
<ul>
<li><p><strong>10 per group</strong>: You&#39;ll only detect if groups differ by ‚â•8 points</p>
</li>
<li><p><strong>30 per group</strong>: You&#39;ll detect if groups differ by ‚â•5 points</p>
</li>
<li><p><strong>50 per group</strong>: You&#39;ll detect if groups differ by ‚â•4 points</p>
</li>
<li><p><strong>100 per group</strong>: You&#39;ll detect if groups differ by ‚â•3 points</p>
</li>
</ul>
<p><strong>If the real difference is smaller than what your sample can detect, the test will likely say &quot;not significant&quot; even though a difference EXISTS.</strong></p>
<p>‚ö†Ô∏è <strong>Below 10 per group</strong>: You can only detect enormous differences. Small/medium differences will be missed, and your test is basically useless.</p>
<h3 id="quick_check_is_my_test_meaningful"><a href="#quick_check_is_my_test_meaningful" class="header-anchor">Quick Check: &quot;Is My Test Meaningful?&quot;</a></h3>
<p><strong>The real question is: &quot;Will my test be able to detect the difference if it exists?&quot;</strong></p>
<p><strong>YES - Your test is meaningful if:</strong></p>
<ul>
<li><p>You expect a LARGE difference &#40;groups differ by ‚â•50&#37; of SD&#41; AND you have ‚â•30 per group</p>
</li>
<li><p>You expect a MEDIUM difference &#40;groups differ by ‚â•40&#37; of SD&#41; AND you have ‚â•50 per group  </p>
</li>
<li><p>You expect a SMALL difference &#40;groups differ by ‚â•30&#37; of SD&#41; AND you have ‚â•100 per group</p>
</li>
</ul>
<p><strong>RISKY - You might miss real differences:</strong></p>
<ul>
<li><p>Your sample sizes are between these thresholds</p>
</li>
<li><p>Consider your results exploratory, not definitive</p>
</li>
</ul>
<p><strong>NO - Your test is likely useless:</strong></p>
<ul>
<li><p>You have &lt;10 per group &#40;unless you expect enormous differences&#41;</p>
</li>
<li><p>You expect a small difference but have &lt;100 per group</p>
</li>
</ul>
<p><strong>Bottom line</strong>: More samples &#61; able to detect smaller differences. Fewer samples &#61; can only detect big, obvious differences.</p>
<hr />
<h2 id="unequal_sample_sizes_details"><a href="#unequal_sample_sizes_details" class="header-anchor">Unequal Sample Sizes &#40;Details&#41;</a></h2>
<h3 id="understanding_effective_sample_size"><a href="#understanding_effective_sample_size" class="header-anchor">Understanding Effective Sample Size</a></h3>
<p>When group sizes differ, statistical power depends on the <strong>harmonic mean</strong>:</p>
\[n_{\text{eff}} = \frac{2n_1 n_2}{n_1 + n_2}\]
<p>This represents the &quot;equivalent balanced sample size&quot; in terms of statistical power.</p>
<h3 id="important_implications"><a href="#important_implications" class="header-anchor">Important Implications</a></h3>
<ol>
<li><p><strong>Power loss with imbalance</strong>: The effective sample size is always ‚â§ the average of \(n_1\) and \(n_2\)</p>
</li>
<li><p><strong>Extreme example</strong>: </p>
<ul>
<li><p>Balanced: \(n_1 = n_2 = 50\) ‚Üí \(n_{\text{eff}} = 50\)</p>
</li>
<li><p>Imbalanced: \(n_1 = 80, n_2 = 20\) ‚Üí \(n_{\text{eff}} = 32\) &#40;36&#37; power loss&#33;&#41;</p>
</li>
<li><p>Imbalanced: \(n_1 = 90, n_2 = 10\) ‚Üí \(n_{\text{eff}} = 18\) &#40;64&#37; power loss&#33;&#41;</p>
</li>
</ul>
</li>
<li><p><strong>Rule</strong>: To maximize power with fixed total N, use <strong>equal group sizes</strong></p>
</li>
</ol>
<h3 id="practical_example"><a href="#practical_example" class="header-anchor">Practical Example</a></h3>
<p>Suppose you want 80&#37; power to detect \(d = 0.5\) &#40;medium effect&#41; with Œ±&#61;0.05:</p>
<ul>
<li><p><strong>Balanced design</strong>: \(n_1 = n_2 = 63\) &#40;Total N &#61; 126&#41;</p>
</li>
<li><p><strong>Imbalanced 2:1</strong>: \(n_1 = 84, n_2 = 42\) &#40;Total N &#61; 126, but \(n_{\text{eff}} = 56\), underpowered&#33;&#41;</p>
</li>
<li><p><strong>To achieve same power with 2:1 ratio</strong>: Need \(n_1 = 95, n_2 = 47\) &#40;Total N &#61; 142&#41;</p>
</li>
</ul>
<h3 id="computing_required_unequal_sample_sizes"><a href="#computing_required_unequal_sample_sizes" class="header-anchor">Computing Required Unequal Sample Sizes</a></h3>
<p>If you must use a specific ratio \(r = n_1/n_2\), and you need effective sample size \(n_{\text{eff}}\):</p>
\[n_2 = n_{\text{eff}} \cdot \frac{r+1}{2r}\]
\[n_1 = r \cdot n_2\]
<p><strong>Example with 3:1 ratio and medium effect:</strong></p>
<ul>
<li><p>Need \(n_{\text{eff}} \approx 63\) for 80&#37; power</p>
</li>
<li><p>With \(r = 3\): \(n_2 = 63 \times \frac{4}{6} = 42\), \(n_1 = 126\)</p>
</li>
<li><p>Total N &#61; 168 vs. 126 for balanced design &#40;33&#37; more participants needed&#41;</p>
</li>
</ul>
<hr />
<h2 id="rule_of_thumb"><a href="#rule_of_thumb" class="header-anchor">Rule of Thumb</a></h2>
<p><strong>If you have no prior information:</strong></p>
<ul>
<li><p>Aim for <strong>minimum 30 per group</strong> to rely on Central Limit Theorem</p>
</li>
<li><p>‚ö†Ô∏è Warning: 30 may be too small to detect small-to-medium effects</p>
</li>
</ul>
<p><strong>Should you exclude samples with &lt;30 data points?</strong></p>
<p><strong>It depends on your goal:</strong></p>
<p><strong>YES, exclude if:</strong></p>
<ul>
<li><p>You&#39;re doing a <strong>rigorous confirmatory study</strong> where you need reliable statistical inference</p>
</li>
<li><p>You need to detect <strong>medium or smaller effects</strong> &#40;30 is borderline at best&#41;</p>
</li>
<li><p>You have <strong>multiple groups</strong> to compare and can&#39;t afford underpowered comparisons</p>
</li>
<li><p>The cost of false negatives &#40;missing real effects&#41; is high</p>
</li>
</ul>
<p><strong>NO, keep if:</strong></p>
<ul>
<li><p>You&#39;re doing <strong>exploratory analysis</strong> and just want to see patterns</p>
</li>
<li><p>You expect <strong>very large effects</strong> &#40;d &gt; 0.8&#41; - small samples can still detect these</p>
</li>
<li><p>It&#39;s a <strong>pilot study</strong> or preliminary investigation</p>
</li>
<li><p>You&#39;re willing to interpret results cautiously and follow up with larger samples</p>
</li>
<li><p>Excluding the group would create bias &#40;e.g., always excluding rare conditions&#41;</p>
</li>
</ul>
<p><strong>Better approach than hard cutoffs:</strong></p>
<ol>
<li><p>Calculate \(n_{\text{eff}}\) and \(d_{\min}\) for each comparison</p>
</li>
<li><p>Keep groups where \(d_{\min}\) is reasonable for your expected effect size</p>
</li>
<li><p>Report power calculations alongside results</p>
</li>
<li><p>Be transparent about which comparisons are underpowered</p>
</li>
</ol>
<p><strong>Example:</strong> If you have groups with n&#61;25, n&#61;35, n&#61;50, n&#61;100:</p>
<ul>
<li><p>Don&#39;t automatically exclude n&#61;25</p>
</li>
<li><p>Instead: Note that n&#61;25 can only detect d‚â•0.56, n&#61;35 can detect d‚â•0.47, etc.</p>
</li>
<li><p>Decide based on whether these thresholds match your expected effects</p>
</li>
</ul>
<hr />
<h2 id="what_you_need_to_calculate_sample_size"><a href="#what_you_need_to_calculate_sample_size" class="header-anchor">What You Need to Calculate Sample Size</a></h2>
<p>Provide <strong>either</strong>:</p>
<p><strong>Option A:</strong> Raw parameters</p>
<ul>
<li><p>Estimated standard deviation &#40;\(\sigma\)&#41;</p>
</li>
<li><p>Minimum detectable difference &#40;\(\delta\)&#41;</p>
</li>
</ul>
<p><strong>Option B:</strong> Effect size</p>
<ul>
<li><p>Cohen&#39;s \(d = \delta/\sigma\) you want to detect</p>
<ul>
<li><p>Small: \(d = 0.2\)</p>
</li>
<li><p>Medium: \(d = 0.5\)</p>
</li>
<li><p>Large: \(d = 0.8\)</p>
</li>
</ul>
</li>
</ul>
<p><strong>Plus:</strong></p>
<ul>
<li><p>Desired significance level &#40;Œ±, typically 0.05&#41;</p>
</li>
<li><p>Desired power &#40;1‚àíŒ≤, typically 0.80 or 0.90&#41;</p>
</li>
<li><p>Study design &#40;paired vs. independent&#41;</p>
</li>
<li><p>Number of groups/comparisons</p>
</li>
</ul>
<hr />
<h2 id="quick_reference_table"><a href="#quick_reference_table" class="header-anchor">Quick Reference Table</a></h2>
<table><tr><th align="right">Desired Power</th><th align="right">Œ± &#61; 0.05</th><th align="right">Cohen&#39;s d &#61; 0.5</th><th align="right">n per group</th></tr><tr><td align="right">70&#37;</td><td align="right">Two-sided</td><td align="right">Medium effect</td><td align="right">~52</td></tr><tr><td align="right"><strong>80&#37;</strong></td><td align="right"><strong>Two-sided</strong></td><td align="right"><strong>Medium effect</strong></td><td align="right"><strong>~63</strong></td></tr><tr><td align="right">90&#37;</td><td align="right">Two-sided</td><td align="right">Medium effect</td><td align="right">~85</td></tr><tr><td align="right">95&#37;</td><td align="right">Two-sided</td><td align="right">Medium effect</td><td align="right">~105</td></tr></table>
<div class="page-foot">
    Contact me by <a href="mailto:skchu@wustl.edu">E-mail</a> | <a href="https://github.com/kchu25">Github</a> | <a href="https://www.linkedin.com/in/kchu1/">Linkedin</a>
    <br>
    This work is licensed under <a href="http://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a>.  Last modified: December 12, 2025.
    <br>
    Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia language</a>.
</div>
</div><!-- CONTENT ENDS HERE -->
    
        <script src="/libs/katex/katex.min.js"></script>
<script src="/libs/katex/contrib/auto-render.min.js"></script>
<script>renderMathInElement(document.body)</script>

    
    
        <script src="/libs/highlight/highlight.min.js"></script>
<script>hljs.highlightAll();hljs.configure({tabReplace: '    '});</script>

    
  </body>
</html>
